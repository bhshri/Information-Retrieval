{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xx2QHjGdod2q"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "data = json.load(open('/content/drive/My Drive/Information_Retrieval/dev-v1.1_full.json','r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "colab_type": "code",
    "id": "iUC8sV-ks0O8",
    "outputId": "8bb35e73-3d8c-4ce7-8d1e-261b391d0025"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/brown.zip.\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/conll2000.zip.\n",
      "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "!python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9-Gwi_uaFkpL"
   },
   "source": [
    "# **WORD2VEC MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cqrUy6AAqV5v"
   },
   "outputs": [],
   "source": [
    "corpus = []\n",
    "\n",
    "for l in data['data']:\n",
    "  for para in l['paragraphs']:\n",
    "    corpus.append(para['context'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ZE5H291_pfta",
    "outputId": "81d5f0b9-a46d-475c-f912-3028e58d04fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2067"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z9ycUGNt3322"
   },
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "from gensim import utils\n",
    "\n",
    "class MyCorpus(object):\n",
    "    def __iter__(self): \n",
    "        preprocessed_text_column = corpus\n",
    "        for line in preprocessed_text_column:\n",
    "            # assume there's one document per line, tokens separated by whitespace\n",
    "            yield utils.simple_preprocess(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LDTo9lbc333K"
   },
   "outputs": [],
   "source": [
    "import gensim.models\n",
    "sentences = MyCorpus()\n",
    "skipGramModel = gensim.models.Word2Vec(sentences=sentences,sg = 1,workers=4,iter = 70,batch_words=1,min_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QGG-zGHqilJP"
   },
   "source": [
    "# **COSINE SIMILARITY**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "J9cE70zGyTMC",
    "outputId": "4190e55a-c34a-4a46-c140-743a758b5218"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.982026530853962 Exact Match:0.0005183436042158614\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "correctly_retrieved_answers = 0\n",
    "total_retrieved_answers = 0\n",
    "exact_matches = 0\n",
    "total_number_of_answers = 0\n",
    "for title in data['data']:\n",
    "  for para in title['paragraphs']:\n",
    "\n",
    "    #######################Paragraph Context#########################\n",
    "    context = para['context']\n",
    "    sentence_list = [item.raw for item in TextBlob(context).sentences]\n",
    "    sentence_vectors = []\n",
    "    for s in sentence_list:   \n",
    "        words_in_s = utils.simple_preprocess(s)\n",
    "        s_vector = np.zeros(100)\n",
    "        #generating vector for the each sentence in the context\n",
    "        for word in words_in_s:\n",
    "          try:\n",
    "            s_vector+=skipGramModel.wv.get_vector(word)\n",
    "          except:\n",
    "            pass\n",
    "        sentence_vectors.append(s_vector)\n",
    "    \n",
    "    #######################Questions and Answers######################\n",
    "    questions_and_answers = para['qas']\n",
    "    #it is a list of dicts\n",
    "    for qa in questions_and_answers:\n",
    "      answers = qa['answers']\n",
    "      answers_text = []\n",
    "      for answer in answers:\n",
    "        answers_text.append(answer['text'])\n",
    "      actual_number_of_answers = len(answers_text)\n",
    "      #####################Calculating Question Vector################\n",
    "      question = qa['question']\n",
    "      processed_question = utils.simple_preprocess(question)\n",
    "      question_vector = np.zeros(100)\n",
    "      for word in processed_question:\n",
    "        try:\n",
    "          question_vector+=skipGramModel.wv.get_vector(word)\n",
    "        except:\n",
    "          pass\n",
    "\n",
    "      ######################Finding Top Matching Sentences###########\n",
    "      similarity = []\n",
    "      for i in range(len(sentence_vectors)):\n",
    "        sentence_vector = sentence_vectors[i]\n",
    "        similarity.append([cosine_similarity([sentence_vector],[question_vector])[0][0],i])\n",
    "\n",
    "      similarity.sort(reverse=True)\n",
    "      top_matching_sentences = [ sentence_list[i] for v,i in similarity[0:actual_number_of_answers] ]\n",
    "      ###################Calculating F1-score and Exact Match###########\n",
    "      total_number_of_answers+=actual_number_of_answers\n",
    "      total_retrieved_answers+=len(top_matching_sentences)\n",
    "\n",
    "      for ans in answers_text:\n",
    "        for sentence in top_matching_sentences:\n",
    "          if ans.strip() in sentence:\n",
    "            correctly_retrieved_answers+=1\n",
    "            break\n",
    "      count = 0\n",
    "      if correctly_retrieved_answers > 0:\n",
    "        for i in range(len(answers_text)):\n",
    "          for j in range(len(top_matching_sentences)):\n",
    "            if answers_text[i] == top_matching_sentences[j]:\n",
    "              count+=1\n",
    "              break\n",
    "      exact_matches+=count  \n",
    "\n",
    "\n",
    "precision = correctly_retrieved_answers/total_retrieved_answers\n",
    "recall = correctly_retrieved_answers/total_number_of_answers\n",
    "f1_score = 0\n",
    "if precision+recall != 0:\n",
    "    f1_score = 2*precision*recall/(precision+recall)\n",
    "\n",
    "print(\"F1-Score: {} Exact Match:{}\".format(f1_score,exact_matches/total_number_of_answers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z5QH7VM4iyBb"
   },
   "source": [
    "# **DEPENDENCY GRAPH**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "zzdcKCzK0Wzq",
    "outputId": "4534584e-f907-4d56-bfb1-e5e57f88ad50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.22880083440159077 Exact Match:0.0001727812014052871\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import spacy\n",
    "en_nlp = spacy.load('en')\n",
    "\n",
    "f1_scores = []\n",
    "exact_matches = 0\n",
    "total_number_of_answers = 0\n",
    "for title in data['data']:\n",
    "  for para in title['paragraphs']:\n",
    "\n",
    "    #######################Paragraph Context#########################\n",
    "    context = para['context']\n",
    "    sentence_list = [item.raw for item in TextBlob(context).sentences]\n",
    "    sentence_vectors = []\n",
    "    sentence_root_words = []\n",
    "    for s in sentence_list:   \n",
    "        words_in_s = utils.simple_preprocess(s)\n",
    "        s_vector = np.zeros(100)\n",
    "        #generating vector for the each sentence in the context\n",
    "        for word in words_in_s:\n",
    "          s_vector+=skipGramModel.wv.get_vector(word)\n",
    "        sentence_vectors.append(s_vector)\n",
    "        #finding root word for each sentence in the context\n",
    "        root_word = [str(sent.root)  for sent in en_nlp(s).sents][0]\n",
    "        sentence_root_words.append(root_word)\n",
    "    \n",
    "    #######################Questions and Answers####################################\n",
    "    questions_and_answers = para['qas']\n",
    "    for qa in questions_and_answers:\n",
    "      answers = qa['answers']\n",
    "      answers_text = []\n",
    "      for answer in answers:\n",
    "        answers_text.append(answer['text'])\n",
    "      actual_number_of_answers = len(answers_text)\n",
    "      #####################Calculating Question Vector and Root Word################\n",
    "      question = qa['question']\n",
    "      processed_question = utils.simple_preprocess(TextBlob(question).sentences[0].raw)\n",
    "      question_vector = np.zeros(100)\n",
    "      for word in processed_question:\n",
    "        try:\n",
    "          question_vector+=skipGramModel.wv.get_vector(word)\n",
    "        except:\n",
    "          pass\n",
    "      question_root_word = [str(sent.root)  for sent in en_nlp(question).sents][0]\n",
    "      ######################Finding Top Matching Sentences###########################\n",
    "      top_matching_sentences = [] \n",
    "      top_matching_sentence_vectors = []\n",
    "      for i in range(len(sentence_root_words)):\n",
    "        if question_root_word == sentence_root_words[i]:\n",
    "          top_matching_sentences.append(sentence_list[i])\n",
    "          top_matching_sentence_vectors.append(sentence_vectors[i])\n",
    "\n",
    "      ############Breaking ties using cosine similarity##############################\n",
    "      if len(top_matching_sentences) > actual_number_of_answers:\n",
    "        sim = []\n",
    "        for i in range(len(top_matching_sentence_vectors)):\n",
    "          sim.append([cosine_similarity([question_vector],[top_matching_sentence_vectors[i]])[0][0],top_matching_sentences[i]])\n",
    "        sim.sort(reverse = True)\n",
    "        top_matching_sentences = [sent for simi,sent in sim]\n",
    "\n",
    "      ###################Calculating F1-score and Exact Match########################\n",
    "      total_number_of_answers+=actual_number_of_answers\n",
    "      correctly_retrieved_answers = 0\n",
    "\n",
    "      for ans in answers_text:\n",
    "        for sentence in top_matching_sentences:\n",
    "          if ans.strip() in sentence:\n",
    "            correctly_retrieved_answers+=1\n",
    "            break\n",
    "\n",
    "      count = 0\n",
    "      if correctly_retrieved_answers > 0:\n",
    "        for i in range(len(answers_text)):\n",
    "          for j in range(len(top_matching_sentences)):\n",
    "            if answers_text[i] == top_matching_sentences[j]:\n",
    "              count+=1\n",
    "              break\n",
    "      exact_matches+=count\n",
    "   \n",
    "      precision = correctly_retrieved_answers/len(top_matching_sentences) if len(top_matching_sentences) > 0 else 0\n",
    "      recall = correctly_retrieved_answers/actual_number_of_answers\n",
    "      f1_score = 0\n",
    "      if precision+recall != 0:\n",
    "        f1_score = 2*precision*recall/(precision+recall)\n",
    "      f1_scores.append(f1_score)\n",
    "\n",
    "print(\"F1-Score: {} Exact Match:{}\".format(sum(f1_scores)/len(f1_scores),exact_matches/total_number_of_answers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5JIVp9MyDjZR"
   },
   "source": [
    "# **SUMMARY**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "colab_type": "code",
    "id": "px1TvzZ4DmYQ",
    "outputId": "30fcf71a-9526-4950-b5c3-001b4d75c91a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>METHOD</th>\n",
       "      <th>F1 SCORE</th>\n",
       "      <th>EXACT MATCH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COSINE SIMILARITY</td>\n",
       "      <td>0.9820</td>\n",
       "      <td>0.000518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DEPENDENCY PARSING</td>\n",
       "      <td>0.2288</td>\n",
       "      <td>0.000172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               METHOD  F1 SCORE  EXACT MATCH\n",
       "0   COSINE SIMILARITY    0.9820     0.000518\n",
       "1  DEPENDENCY PARSING    0.2288     0.000172"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = [['COSINE SIMILARITY',0.9820,0.000518],['DEPENDENCY PARSING',0.2288,0.000172]]\n",
    "dataframe = pd.DataFrame(data=data,columns = ['METHOD','F1 SCORE','EXACT MATCH'])\n",
    "dataframe"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "9-Gwi_uaFkpL",
    "QGG-zGHqilJP",
    "z5QH7VM4iyBb",
    "5JIVp9MyDjZR"
   ],
   "name": "Assignment_7_201911003.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
